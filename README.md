# Литературный ассистент по роману «Война и мир»

Проект представляет собой **интеллектуального литературного путеводителя** по роману Л.Н. Толстого «Война и мир».  
Система отвечает на вопросы **строго на основе текста романа**, используя контекстный поиск и генерацию с помощью локальной LLM.  
Архитектура построена на микросервисах и полностью контейнеризована с помощью Docker.

---

## Ключевые возможности

- **Точность**: Ответы основаны **только на тексте романа**, без внешних знаний.
- **Контекстный поиск**: Извлекает релевантные фрагменты с учётом упомянутых персонажей и локаций.
- **Потоковая генерация**: Поддержка SSE (Server-Sent Events) для мгновенного отображения ответа во фронтенде.
- **Извлечение сущностей**: Автоматическое определение персонажей и локаций из запроса и текста.
- **Расширяемость**: Модульная архитектура на основе LangGraph и LangChain.

---

## Стек технологий

| Компонент | Технология |
|----------|------------|
| **LLM** | Локально, через Ollama |
| **Бэкенд** | Python 3.13, FastAPI, LangChain, LangGraph |
| **Векторное хранилище** | ChromaDB |
| **Фронтенд** | FastAPI + Jinja2 (SSR), HTML/JS для SSE |
| **Контейнеризация** | Docker, Docker Compose |

---

## Установка и запуск

### 1. Требования

- Docker и Docker Compose
- NVIDIA GPU (рекомендуется ≥16 ГБ VRAM для `qwen3:14b`)
- Доступ к интернету (для первоначальной загрузки моделей)

### 2. Подготовка

1. Клонируйте репозиторий:
   ```bash
   git clone https://github.com/Golden-Gekko/war-and-peace-qa-bot
   cd war-and-peace-qa-bot
   ```

2. Создайте `.env` файлы из примеров:
   ```bash
   cp .env.example .env
   cp backend/.env.example backend/.env
   cp frontend/.env.example frontend/.env
   ```

3. Убедитесь, что в `backend/.env` указаны нужные модели

4. Убедитесь в наличии файлов `.json` в папке JSON

### 3. Сборка и запуск

```bash
docker-compose up --build
```

> При первом запуске:
> - Ollama загрузит указанные модели.
> - Скрипт `db_filling.py` заполнит ChromaDB.
> - Это может занять некоторое время, в зависимости от скорости интернет-соединения

### 4. Использование

- Фронтенд: [http://localhost:8000](http://localhost:8000)
- API (для разработчиков): `POST http://localhost:8000/api/generate`
  ```json
  { "message": "Что делал Пьер в Бородино?" }
  ```

---

## Структура проекта

```
.
├── backend/               # FastAPI-бэкенд
│   ├── api/               # Агент, инструменты, промпты
│   ├── db/                # Работа с ChromaDB
│   ├── utils/             # Парсер EPUB, логгер
│   └── db_filling.py      # Инициализация базы знаний
├── frontend/              # SSR-фронтенд на FastAPI + Jinja2
├── docker-compose.yml     # Оркестрация сервисов
├── Dockerfile.backend     # Контейнер бэкенда
├── Dockerfile.frontend    # Контейнер фронтенда
└── requirements.txt       # Зависимости Python
```

---

## Важно

- Проект **не использует внешние знания** — если информация отсутствует в тексте романа, будет возвращено:  
  > «В тексте "Войны и мира" это не упоминается».
- Для работы с GPU в Docker требуется установленный [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html).
- При изменении EPUB-файла или моделей — удалите том `chroma_data`, сгенерируйте новые данные и пересоберите контейнер:
  ```bash
  docker-compose down -v
  docker-compose up --build
  ```распарсит EPUB, извлечёт сущности, создаст эмбеддинги и 

### `db_filling.py`

Скрипт отвечает за **парсинг EPUB-файла романа**, **извлечение литературных сущностей** (персонажи, локации), **создание эмбеддингов** и **заполнение векторной базы ChromaDB**.  
Он используется один раз при первом запуске проекта или при необходимости обновления исходного текста.

#### Аргументы командной строки

| Аргумент | Описание |
|----------|----------|
| `file_path` | Путь к EPUB-файлу (например, `war_and_peace.epub`) |
| `start_from` | Номер раздела (главы), с которого начать обработку. Полезно при прерванной загрузке. Нумерация начинается с **1**. |

> Если `file_path` не указан, скрипт попытается загрузить уже существующие JSON-файлы из папки `./JSON` и наполнить ими ChromaDB.

#### Примеры запуска

##### 1. Полная обработка EPUB-файла с начала
```bash
python db_filling.py war_and_peace.epub
```

##### 2. Возобновление обработки с 15-го раздела (если процесс был прерван)
```bash
python db_filling.py war_and_peace.epub 15
```

> Скрипт сохраняет каждый обработанный раздел в отдельный JSON-файл (`part_1.json`, `part_2.json`, …).  
> При повторном запуске с тем же `file_path` и `start_from=N` он **перезапишет** файлы начиная с `part_N.json`.

##### 3. Заполнение ChromaDB из уже существующих JSON-файлов (без парсинга EPUB)
```bash
python db_filling.py
```
> В этом случае:
> - EPUB не читается.
> - Используется папка `./JSON` рядом со скриптом.
> - Все `*.json` файлы в ней загружаются в ChromaDB.

#### Важные настройки (в коде)

- `CHUNK_SIZE = 2048` — максимальная длина фрагмента текста.
- `CHUNK_OVERLAP = 256` — перекрытие фрагментов текста.
- `EMBEDDING_SIZE = 1024` — ожидаемая размерность эмбеддинга (для `bge-m3`).

---

## Благодарности

- [![Ollama](https://img.shields.io/badge/Ollama-black?logo=ollama&logoColor=white)](https://ollama.com) — за обеспечение локального запуска LLM
- [![LangChain](https://img.shields.io/badge/LangChain-blue?logo=langchain)](https://langchain.com) — за возможность оркестрации агентов
- [![ChromaDB](https://img.shields.io/badge/ChromaDB-purple?logo=chromadb)](https://www.trychroma.com) — за реализацию векторного поиска
- [![L.N. Tolstoy](https://img.shields.io/badge/Л._Н._Толстой-8B4513)](https://tolstoy.ru/creativity/fiction/1071/) — за "Войну и мир"
